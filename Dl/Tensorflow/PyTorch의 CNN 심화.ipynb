{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "# http://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torchvision에서 가져오는 데이터는 10개의 사물의 분류 이미지\n",
    "    - Cifar-10 데이터\n",
    "        - 6만장\n",
    "        - RGB\n",
    "        - 높이, 너비는 각각 32\n",
    "        - 비행기, 자동차, ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170500096it [00:59, 2791145.83it/s]                                                                                    "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "train_dataset = datasets.CIFAR10('./data', train=True, \n",
    "                                 download=True, transform=transforms.ToTensor())\n",
    "test_dataset  = datasets.CIFAR10('./data', train=False, \n",
    "                                 transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000, torchvision.datasets.cifar.CIFAR10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset), type(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print( train_dataset.classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45101"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤 이미지\n",
    "idx = torch.randint( 0, len(train_dataset), (1,) ).item()\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 32, 32]), 9, 'truck')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image = train_dataset[idx][0]\n",
    "random_image.shape, train_dataset[idx][1], train_dataset.classes[train_dataset[idx][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터의 차원 이동을 하여 그릴수 있게 조정\n",
    "plt.imshow( random_image.numpy().transpose(1,2,0) )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 'cpu', 30, 180)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경변수, 학습용 상수, 설정값\n",
    "BATCH  = 128\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "STEP   = 30\n",
    "PRINT_STEP = 180\n",
    "\n",
    "BATCH, DEVICE, STEP, PRTINT_STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader( train_dataset, batch_size=BATCH, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader  = DataLoader( test_dataset, batch_size=BATCH, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 79)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNN 클레스 생성\n",
    "    - 합성곱 형태 정의\n",
    "        - case 1 : 합성곱층=nn.Conv2D+nn.ReLU, 풀링층:nn.MaxPool2d\n",
    "        - **case 2 : 합성곱층=nn.Conv2D+nn.ReLU,nn.MaxPool2d**\n",
    "        <img src='./8.cnn_layer.jpeg' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td><img src='8.cnn_value.jpeg'></td>\n",
    "    <td><img src='6.cnn_shape.jpeg'></td>\n",
    "</tr>\n",
    "\n",
    "- W(or H) = (W(in) + 2*P - K) /S + 1를 이용하여 레이어를 통과할때 크기를 계산\n",
    "- feature의 수는 = 채널수 * 이미지세로* 이미지가로\n",
    "\n",
    "- nn.Module\n",
    "    - 신경망 모듈의 기본 클레스\n",
    "    - 모든 모델은 이 클레스를 상속받아야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):    \n",
    "    def __init__(self):\n",
    "        # 부모 생성자 호출\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # 합성곱층 생성\n",
    "        self.conv1  = nn.Conv2d( in_channels=3,out_channels=8,kernel_size=5,stride=1 \n",
    "                                 ,padding=1)\n",
    "        self.conv2  = nn.Conv2d( in_channels=8,out_channels=16,kernel_size=2,stride=1\n",
    "                                ,padding=0)        \n",
    "        # 렐루 생성\n",
    "        self.relu   = nn.ReLU(inplace=True)        \n",
    "        # 풀링 생성\n",
    "        self.pool   = nn.MaxPool2d( kernel_size=2, stride=2 )\n",
    "        \n",
    "        # 전결합층 생성\n",
    "        # [batch, 16, 7, 7] => [ batch, 16*7*7] => [batch, 784] => reshape == view\n",
    "        # x.view( batch크기로 지정할다 , 나머지는 2차원에맞겟끔알아서펴라 )\n",
    "        self.flatten = lambda x: x.view( x.size(0) , -1 )\n",
    "        self.fc      = nn.Linear( 784, 10 )\n",
    "        \n",
    "    '''\n",
    "    - 모든 호출에서 사용하는 연산 정의\n",
    "    - 모든 서브클레스들(CNN)은 이 함수를 반드시 재정의 해야 한다\n",
    "    - 층을 정의한다(레이어 정의)\n",
    "    - x:입력 텐서, 입력 데이터\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        # 합성곱층의 체이닝\n",
    "        # 컨볼류젼1\n",
    "        x = self.conv1(x)\n",
    "        # 렐루\n",
    "        x = self.relu(x)\n",
    "        # 풀링\n",
    "        x = self.pool(x)\n",
    "        # 컨볼류젼2\n",
    "        x = self.conv2(x)\n",
    "        # 렐루\n",
    "        x = self.relu(x)\n",
    "        # 풀링\n",
    "        x = self.pool(x)\n",
    "        # 전결합층\n",
    "        x = self.flatten(x)        \n",
    "        x = self.fc(x)\n",
    "        # 출력층은 작업후 처리로 설정\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 선언\n",
    "model     = CNN().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수, 크로스엔트로피\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저, 확률적 경사 하강법\n",
    "optimizer = optim.Adam( model.parameters() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils_mod import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 1 (00.00%)  \tLoss: 2.3056\n",
      "Train Step: 1 (46.08%)  \tLoss: 1.8413\n",
      "Train Step: 1 (92.16%)  \tLoss: 1.6227\n",
      "Test set: Average loss: 1.6054, Accuracy: 4344/10000 (43.44%)\n",
      "\n",
      "Train Step: 2 (00.00%)  \tLoss: 1.7687\n",
      "Train Step: 2 (46.08%)  \tLoss: 1.4208\n",
      "Train Step: 2 (92.16%)  \tLoss: 1.3774\n",
      "Test set: Average loss: 1.4682, Accuracy: 4830/10000 (48.30%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 3 (00.00%)  \tLoss: 1.3777\n",
      "Train Step: 3 (46.08%)  \tLoss: 1.4554\n",
      "Train Step: 3 (92.16%)  \tLoss: 1.4534\n",
      "Test set: Average loss: 1.3997, Accuracy: 5133/10000 (51.33%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 4 (00.00%)  \tLoss: 1.4247\n",
      "Train Step: 4 (46.08%)  \tLoss: 1.3921\n",
      "Train Step: 4 (92.16%)  \tLoss: 1.4975\n",
      "Test set: Average loss: 1.3947, Accuracy: 5140/10000 (51.40%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 5 (00.00%)  \tLoss: 1.3592\n",
      "Train Step: 5 (46.08%)  \tLoss: 1.2979\n",
      "Train Step: 5 (92.16%)  \tLoss: 1.4453\n",
      "Test set: Average loss: 1.3069, Accuracy: 5404/10000 (54.04%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 6 (00.00%)  \tLoss: 1.4588\n",
      "Train Step: 6 (46.08%)  \tLoss: 1.1462\n",
      "Train Step: 6 (92.16%)  \tLoss: 1.2217\n",
      "Test set: Average loss: 1.2715, Accuracy: 5531/10000 (55.31%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 7 (00.00%)  \tLoss: 1.2732\n",
      "Train Step: 7 (46.08%)  \tLoss: 1.2891\n",
      "Train Step: 7 (92.16%)  \tLoss: 1.2398\n",
      "Test set: Average loss: 1.2626, Accuracy: 5578/10000 (55.78%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 8 (00.00%)  \tLoss: 1.2736\n",
      "Train Step: 8 (46.08%)  \tLoss: 1.2269\n",
      "Train Step: 8 (92.16%)  \tLoss: 1.2527\n",
      "Test set: Average loss: 1.2344, Accuracy: 5681/10000 (56.81%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 9 (00.00%)  \tLoss: 1.2146\n",
      "Train Step: 9 (46.08%)  \tLoss: 1.3576\n",
      "Train Step: 9 (92.16%)  \tLoss: 1.0857\n",
      "Test set: Average loss: 1.2612, Accuracy: 5568/10000 (55.68%)\n",
      "\n",
      "Train Step: 10 (00.00%)  \tLoss: 1.0769\n",
      "Train Step: 10 (46.08%)  \tLoss: 1.3550\n",
      "Train Step: 10 (92.16%)  \tLoss: 1.3302\n",
      "Test set: Average loss: 1.2186, Accuracy: 5737/10000 (57.37%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 11 (00.00%)  \tLoss: 0.9701\n",
      "Train Step: 11 (46.08%)  \tLoss: 1.1550\n",
      "Train Step: 11 (92.16%)  \tLoss: 0.9522\n",
      "Test set: Average loss: 1.1890, Accuracy: 5856/10000 (58.56%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 12 (00.00%)  \tLoss: 1.2520\n",
      "Train Step: 12 (46.08%)  \tLoss: 1.0824\n",
      "Train Step: 12 (92.16%)  \tLoss: 1.1076\n",
      "Test set: Average loss: 1.1843, Accuracy: 5871/10000 (58.71%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 13 (00.00%)  \tLoss: 1.0807\n",
      "Train Step: 13 (46.08%)  \tLoss: 1.1854\n",
      "Train Step: 13 (92.16%)  \tLoss: 1.2007\n",
      "Test set: Average loss: 1.1827, Accuracy: 5900/10000 (59.00%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 14 (00.00%)  \tLoss: 1.1723\n",
      "Train Step: 14 (46.08%)  \tLoss: 1.0810\n",
      "Train Step: 14 (92.16%)  \tLoss: 1.1814\n",
      "Test set: Average loss: 1.1653, Accuracy: 5908/10000 (59.08%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 15 (00.00%)  \tLoss: 0.9198\n",
      "Train Step: 15 (46.08%)  \tLoss: 1.1624\n",
      "Train Step: 15 (92.16%)  \tLoss: 1.2748\n",
      "Test set: Average loss: 1.1629, Accuracy: 5915/10000 (59.15%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 16 (00.00%)  \tLoss: 1.1194\n",
      "Train Step: 16 (46.08%)  \tLoss: 1.0502\n",
      "Train Step: 16 (92.16%)  \tLoss: 1.0996\n",
      "Test set: Average loss: 1.1741, Accuracy: 5904/10000 (59.04%)\n",
      "\n",
      "Train Step: 17 (00.00%)  \tLoss: 1.2803\n",
      "Train Step: 17 (46.08%)  \tLoss: 1.1113\n",
      "Train Step: 17 (92.16%)  \tLoss: 1.0876\n",
      "Test set: Average loss: 1.1580, Accuracy: 5969/10000 (59.69%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 18 (00.00%)  \tLoss: 1.0791\n",
      "Train Step: 18 (46.08%)  \tLoss: 1.0190\n",
      "Train Step: 18 (92.16%)  \tLoss: 1.1439\n",
      "Test set: Average loss: 1.1590, Accuracy: 5944/10000 (59.44%)\n",
      "\n",
      "Train Step: 19 (00.00%)  \tLoss: 1.0847\n",
      "Train Step: 19 (46.08%)  \tLoss: 1.0458\n",
      "Train Step: 19 (92.16%)  \tLoss: 1.2389\n",
      "Test set: Average loss: 1.1394, Accuracy: 6062/10000 (60.62%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 20 (00.00%)  \tLoss: 1.0221\n",
      "Train Step: 20 (46.08%)  \tLoss: 1.1404\n",
      "Train Step: 20 (92.16%)  \tLoss: 1.2318\n",
      "Test set: Average loss: 1.1491, Accuracy: 5984/10000 (59.84%)\n",
      "\n",
      "Train Step: 21 (00.00%)  \tLoss: 1.0315\n",
      "Train Step: 21 (46.08%)  \tLoss: 1.0722\n",
      "Train Step: 21 (92.16%)  \tLoss: 1.2209\n",
      "Test set: Average loss: 1.1290, Accuracy: 6113/10000 (61.13%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 22 (00.00%)  \tLoss: 1.1026\n",
      "Train Step: 22 (46.08%)  \tLoss: 0.9731\n",
      "Train Step: 22 (92.16%)  \tLoss: 1.1759\n",
      "Test set: Average loss: 1.1234, Accuracy: 6105/10000 (61.05%)\n",
      "\n",
      "Train Step: 23 (00.00%)  \tLoss: 1.1456\n",
      "Train Step: 23 (46.08%)  \tLoss: 1.2453\n",
      "Train Step: 23 (92.16%)  \tLoss: 1.0848\n",
      "Test set: Average loss: 1.1304, Accuracy: 6099/10000 (60.99%)\n",
      "\n",
      "Train Step: 24 (00.00%)  \tLoss: 1.1791\n",
      "Train Step: 24 (46.08%)  \tLoss: 1.0031\n",
      "Train Step: 24 (92.16%)  \tLoss: 0.9901\n",
      "Test set: Average loss: 1.1104, Accuracy: 6179/10000 (61.79%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 25 (00.00%)  \tLoss: 1.0112\n",
      "Train Step: 25 (46.08%)  \tLoss: 0.9292\n",
      "Train Step: 25 (92.16%)  \tLoss: 1.1050\n",
      "Test set: Average loss: 1.1124, Accuracy: 6150/10000 (61.50%)\n",
      "\n",
      "Train Step: 26 (00.00%)  \tLoss: 1.0301\n",
      "Train Step: 26 (46.08%)  \tLoss: 1.0718\n",
      "Train Step: 26 (92.16%)  \tLoss: 0.9303\n",
      "Test set: Average loss: 1.1099, Accuracy: 6156/10000 (61.56%)\n",
      "\n",
      "Train Step: 27 (00.00%)  \tLoss: 1.0655\n",
      "Train Step: 27 (46.08%)  \tLoss: 1.0432\n",
      "Train Step: 27 (92.16%)  \tLoss: 0.9747\n",
      "Test set: Average loss: 1.1419, Accuracy: 6029/10000 (60.29%)\n",
      "\n",
      "Train Step: 28 (00.00%)  \tLoss: 0.9071\n",
      "Train Step: 28 (46.08%)  \tLoss: 0.9052\n",
      "Train Step: 28 (92.16%)  \tLoss: 1.0409\n",
      "Test set: Average loss: 1.1129, Accuracy: 6139/10000 (61.39%)\n",
      "\n",
      "Train Step: 29 (00.00%)  \tLoss: 0.9284\n",
      "Train Step: 29 (46.08%)  \tLoss: 0.9253\n",
      "Train Step: 29 (92.16%)  \tLoss: 1.0177\n",
      "Test set: Average loss: 1.1187, Accuracy: 6140/10000 (61.40%)\n",
      "\n",
      "Train Step: 30 (00.00%)  \tLoss: 1.0703\n",
      "Train Step: 30 (46.08%)  \tLoss: 0.9202\n",
      "Train Step: 30 (92.16%)  \tLoss: 0.9941\n",
      "Test set: Average loss: 1.1080, Accuracy: 6143/10000 (61.43%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련및 테스트\n",
    "main( model        = model,  # nn.model을 상속받은 클레스\n",
    "      train_loader = train_loader, # 훈련 데이터\n",
    "      test_loader  = test_loader, # 테스트 데이터\n",
    "      loss_func    = loss_func, # 손실함수\n",
    "      optimizer    = optimizer, # 최적화도구\n",
    "      n_step       = STEP, # 반복 스탭, 학습의양 \n",
    "      device       = DEVICE, # cpu, cuda\n",
    "      save_path    = 'cifar10_model_v1.pt', # 학습 완료한 모델의 덤프\n",
    "      print_step   = PRINT_STEP # 수행시 얼마 간격으로 진행 상황을 출력할 것인가?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정확도가 낮다\n",
    "    - 더 큰 모델(이미지)을 이용하여 학습\n",
    "    - 데이터를 더 늘려서 학습\n",
    "    - 배치 정규화를 통해서 학습 성능을 향상, 채널수, 스프라이드, 패딩, 커널사이즈등등\n",
    "    - 알고리즘을 추가하여 개선하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [ ('ch_in', 3),\n",
    "           ('n_in',  32), # 이미지의 사이즈(height or weight, 동일)\n",
    "           ('conv1', (32, 7, 1, 1)  ),('pool1', 2),#(출력채널,커널크기,스프라이드,패딩)\n",
    "           ('conv2', (64, 5, 1, 1)  ),('pool2', 2),\n",
    "           ('conv3', (128, 3, 1, 0) ),('pool3', 2),\n",
    "           ('fc', (250, 50, 10) )\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 (32, 7, 1, 1)\n",
      "pool1 2\n",
      "conv2 (64, 5, 1, 1)\n",
      "pool2 2\n",
      "conv3 (128, 3, 1, 0)\n",
      "pool3 2\n"
     ]
    }
   ],
   "source": [
    "for (k, v) in config:\n",
    "    if 'conv' in k:\n",
    "        print( k, v)\n",
    "    elif 'pool' in k:\n",
    "        print( k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 항목의 값뽑기\n",
    "dict(config)['ch_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컨볼류젼 계층의 총개수?\n",
    "sum([True for k in dict(config) if 'conv' in k])\n",
    "sum([1 for k in dict(config) if 'conv' in k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1]\n",
    "a += [2,3,4]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEx(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CNNEx, self).__init__()\n",
    "        # 컨볼류전 계층 (conv, pool) 병행\n",
    "        self.convs   = nn.Sequential(*self._make_layers(config) )\n",
    "        # 전결합층\n",
    "        # 전결합층 - 플래튼\n",
    "        self.flatten = lambda x: x.view( x.size(0) , -1 )\n",
    "        # 전결합층 - 실제\n",
    "        self.fc      = nn.Sequential(*self._make_layers(config, name='fc') )\n",
    "        pass\n",
    "    # 계층 연결\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    # config에구성에 맞춰서 type에 해당되는 계층을 자동 생성한다\n",
    "    def _make_layers(self, config, name='convs'):\n",
    "        layers = [] # => [ 합,배치정규,렐루,풀, 합,배치정규,렐루,풀, 합,배치정규,렐루,풀]\n",
    "        ch_in  =  dict(config)['ch_in'] # 최초 입력데이터 3\n",
    "        if name == 'convs': #합성곱층을 config에 설정된 값에 따라 완성한다\n",
    "            for (k, v) in config:\n",
    "                if 'conv' in k:   # 합성곱층\n",
    "                    #print( k, v)\n",
    "                    # (32, 7, 1, 1) : (출력채널,커널크기,스프라이드,패딩)\n",
    "                    ch_out, k, s, p = v\n",
    "                    # 레이어 생성\n",
    "                    layers += [ nn.Conv2d(in_channels=ch_in,  # 입력채널\n",
    "                                          out_channels=ch_out,# 출력채널\n",
    "                                          kernel_size=k,      # 커널사이즈\n",
    "                                          stride=s,           # 스프라이드 사이즈\n",
    "                                          padding=p           # 패딩사이즈\n",
    "                                          ),\n",
    "                                nn.BatchNorm2d(ch_out),       # 학습능력을 항상시키기위해\n",
    "                                                              # 배치 정규화 추가\n",
    "                                nn.ReLU(inplace=True)\n",
    "                               ]\n",
    "                    # 핸재 완료된 layer의 출력 채널수를 다음번  layer의 입력채널수로 설정\n",
    "                    ch_in = ch_out\n",
    "                elif 'pool' in k: # 풀링층\n",
    "                    #print( k, v)\n",
    "                    # 커널사이즈와 동일하게 스트라이드 값을 통상 부여\n",
    "                    # 만약 다르게 하고 샆으면 ('pool1', (2, 4)) 값을 추가->수정\n",
    "                    layers += [ nn.MaxPool2d(kernel_size=v, stride=v) ] \n",
    "            \n",
    "        elif name == 'fc':\n",
    "            features = [self._get_fc_input(config)] +  list( dict(config)['fc'] )\n",
    "            # [ 512, 250, 50, 10 ]\n",
    "            # [512, 250] [250, 50]  [50, 10] \n",
    "            for i, (f_in, f_out) in enumerate( zip(features[:-1], features[1:]) ):\n",
    "                # i => 0, 1, 2 중간, 1번째에 렐루를 적용 안하고 나머지는 적용하고                \n",
    "                # 설정\n",
    "                if i == 1:\n",
    "                    layers += [ nn.Linear(f_in, f_out) ]                \n",
    "                else:\n",
    "                    layers += [ nn.Linear(f_in, f_out, nn.ReLU(inplace=True)) ]\n",
    "        else:\n",
    "            print('잘못 입력했습니다 ')            \n",
    "        return layers    \n",
    "    # fc의 입력 채널 채널수 계산    \n",
    "    def _get_fc_input(self, config):\n",
    "        config = dict( config )\n",
    "        n_in   = config['n_in'] # 이미지의 사이즈(세로 혹은 가로) # 32\n",
    "        # 컨볼류젼의 계층이 몇번 존재 했는가? 존재하는가?\n",
    "        convs_cnt = sum([True for k in dict(config) if 'conv' in k]) # 3\n",
    "        # conv1, conv2, conv3 -> 1~3\n",
    "        for i in range(1, convs_cnt+1):\n",
    "            ch_out, k, s, p = config[ 'conv%s'% i ]\n",
    "            pool_k          = config[ 'pool%s'% i ]\n",
    "            # 컨볼류젼 통과후 사이즈\n",
    "            '''\n",
    "            ('conv1', (32, 7, 1, 1)  ),('pool1', 2),\n",
    "            ('conv2', (64, 5, 1, 1)  ),('pool2', 2),\n",
    "            ('conv3', (128, 3, 1, 0) ),('pool3', 2),\n",
    "            '''\n",
    "            # H(out) = ( H(in) + 2*p - k) /s + 1\n",
    "            # (32 + 2*1 - 7) / 1 + 1 = 27 + 1= 28\n",
    "            # (14 + 2*1 - 5) / 1 + 1 = 11+ 1= 12\n",
    "            # (6 + 2*0 - 3) / 1 + 1 = 3+ 1= 4\n",
    "            conv_size_out   = ( n_in + 2*p - k) /s + 1\n",
    "            # 풀링 출력 사이즈 계산\n",
    "            # ( 28 + 2*0 - 2)/2 + 1 = 26/2 + 1 = 13 + 1 = 14\n",
    "            # ( 12 + 2*0 - 2)/2 + 1 = 10/2 + 1 = 5 + 1 = 6\n",
    "            # ( 4 + 2*0 - 2)/2 + 1 = 2/2 + 1 = 1 + 1 = 2\n",
    "            pool_size_out   = ( conv_size_out + 2*0 - pool_k)/ pool_k + 1 \n",
    "            # 다은번 연산을 위해서 이미지의 크기 세팅\n",
    "            n_in = pool_size_out\n",
    "            \n",
    "        # 최종 전결합층에 들어가는 사이즈\n",
    "        # 출력채널(ch_out:128) * n_in(h:2) * n_in(w:2) = 128*2*2 = 512\n",
    "        fc_input = int( ch_out * n_in * n_in )\n",
    "        return fc_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 512 250\n",
      "1 250 50\n",
      "2 50 10\n"
     ]
    }
   ],
   "source": [
    "features = [ 512, 250, 50, 10 ]\n",
    "# [512, 250] [250, 50]  [50, 10] \n",
    "#for i, (f_in, f_out) in enumerate( zip(features[:-1], features[1:]) ):\n",
    "for i, (f_in, f_out) in enumerate( zip([ 512, 250, 50], [250, 50, 10 ]) ):    \n",
    "    print(i, f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(512, 250), (250, 50), (50, 10)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip([ 512, 250, 50], [250, 50, 10 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구동\n",
    "model = CNNEx( config ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam( model.parameters() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 1 (00.00%)  \tLoss: 2.3233\n",
      "Train Step: 1 (46.08%)  \tLoss: 1.3593\n",
      "Train Step: 1 (92.16%)  \tLoss: 1.1018\n",
      "Test set: Average loss: 1.4313, Accuracy: 5085/10000 (50.85%)\n",
      "\n",
      "Train Step: 2 (00.00%)  \tLoss: 1.0613\n",
      "Train Step: 2 (46.08%)  \tLoss: 1.1375\n",
      "Train Step: 2 (92.16%)  \tLoss: 0.9875\n",
      "Test set: Average loss: 1.0074, Accuracy: 6436/10000 (64.36%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 3 (00.00%)  \tLoss: 0.7868\n",
      "Train Step: 3 (46.08%)  \tLoss: 0.9756\n",
      "Train Step: 3 (92.16%)  \tLoss: 0.6765\n",
      "Test set: Average loss: 0.9357, Accuracy: 6751/10000 (67.51%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 4 (00.00%)  \tLoss: 0.6720\n",
      "Train Step: 4 (46.08%)  \tLoss: 0.7525\n",
      "Train Step: 4 (92.16%)  \tLoss: 0.6591\n",
      "Test set: Average loss: 1.3140, Accuracy: 5792/10000 (57.92%)\n",
      "\n",
      "Train Step: 5 (00.00%)  \tLoss: 0.6832\n"
     ]
    }
   ],
   "source": [
    "main( model        = model,  # nn.model을 상속받은 클레스\n",
    "      train_loader = train_loader, # 훈련 데이터\n",
    "      test_loader  = test_loader, # 테스트 데이터\n",
    "      loss_func    = loss_func, # 손실함수\n",
    "      optimizer    = optimizer, # 최적화도구\n",
    "      n_step       = STEP, # 반복 스탭, 학습의양 \n",
    "      device       = DEVICE, # cpu, cuda\n",
    "      save_path    = 'cifar10_model_v2.pt', # 학습 완료한 모델의 덤프\n",
    "      print_step   = PRINT_STEP # 수행시 얼마 간격으로 진행 상황을 출력할 것인가?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
