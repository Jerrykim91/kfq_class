{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "\n",
    "- 합성곱 신경망( CNN:Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1998: 얀 레쿤 교수 제안\n",
    "- 이미지 인식분야에 강력한 성능 발휘\n",
    "- 음성인식, 자연어 처리에도 사용 -> 활용성 높아지고 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 인식 대회 ILSVRC (ImageNet Large Scale Recognition Competition)\n",
    "     - 2010 - NEC-UIUC\n",
    "     - 2011 - XRCE\n",
    "     - 2012 - AlexNet(CNN 알고리즘 기반. 딥러닝시도)\n",
    "     - 2013 - ZFNet\n",
    "     - 2014 - GoogLeNet(Inception v2),  VGGNet 더 유명(간결함, 편의성) \n",
    "     - 2015 - ResNet -> 사람의 정확도(오차율 5%)를 돌파\n",
    "     - 2016 - GoogLeNet-v4\n",
    "     - 2017 - SENet : 2.3% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./7.ILSVRC_랭킹.png' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./5.CNN_도식.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본 구성 \n",
    "    - [입력층] -> [중간층:[합성곱층][풀링층]...[합성곱층][풀링층][전결합층]] -> [출력층]\n",
    "\n",
    "- 중간층\n",
    "    - 합성곱 은닉 계층\n",
    "        - 합성곱층 : Convolution Layer\n",
    "        - 풀링층   : Pooling Layer\n",
    "    - 전결합층(완전 연결 은딕 계층)\n",
    "    <img src='./3.CNN_중간층.jpeg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 합성곱층\n",
    "    - 이미지의 특징을 추출\n",
    "    - 입력 x의 이미지를 일부분을 조금씩 잘라가면서, 가중치 필터 (W)를 적용:(평활화,윤곽선검출) \n",
    "        - 평활화 : 명암의 분포를 균일하게 처리\n",
    "        - 윤곽선 검출 : 이미지 내부의 대상들의 윤곽만 추출\n",
    "    - 움직이는 크기 한 픽셀에서 n칸으로 이동 => 스트라이드(stride)\n",
    "    - 가중치 필터 W의 행렬의 크기는 3x3라고 한다면, 이 가중치 kenel:커널(필터)라고 부르고, 이 구성을 위해서는 편향(바이어스:bias) b도 같이 필요하다\n",
    "    - 입력층 28x28이라면 784개에 대한 가중치를 찾아야 하는데, 연산량도 많고, 시간도 많이 걸리고, 비효율적 => 컨볼류션계층을 도입 => 3x3으로 적용하여 줄인다면 => 가중치는 9개의 값만있으면되니까, 계산량이 적어지고, 학습량도 줄어들어서 효율적이게 된다\n",
    "    - 커널이 1개면 비효율적이니까, 하이퍼파라미터 조정을 통해서 커널의 수, 크기등을 조절하여 계층을 처리할수도 있다\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./dp1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 풀링층\n",
    "    - 합성곱층으로 얻는 특징 맵 C를 축소하는 층\n",
    "    - 특징을 유지한 상태로, 축소\n",
    "    - 직선 인식 -> 직선이 미세하게 흐트러지더라고, 직선으로 인진한다!!\n",
    "    - 축소방법 : 최대 풀링(해단 구성원중에서 최대값을 대표값취한다), \n",
    "                 최소 풀링(해단 구성원중에서 최대값을 최소값취한다), \n",
    "                 평균 풀링(해단 구성원중에서 최대값을 평균값취한다)\n",
    "    <img src='./dp2.png'>                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전결합층\n",
    "    - 각 층의 유닉들을 통합\n",
    "    - 2차원 특징맵들을 1차워으로 전개한다  \n",
    "    - 활성화함수가(렐루, 시그모이드) 사용되고, 특성을 더욱 강조한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cnn기반 텐서플로우를 이용하여 구현\n",
    "    - 데이터 : mnist를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수집\n",
    "mnist = tf.keras.datasets.mnist.load_data( path='mnist.npz' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련용\n",
    "len(mnist[0][0]), len(mnist[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트용\n",
    "len(mnist[1][0]), len(mnist[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이블 확인\n",
    "mnist[0][1][:2] # 백터화 진행.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우의 샘플에서 획득\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-4519f46a92ac>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./data/mnist/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (55000, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련용\n",
    "mnist.train.images.shape, mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# 특정 조건을 만족하는 인덱스\n",
    "print( np.where( mnist.train.labels[0] )[0][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 784의 제곱근\n",
    "pixel_size = int(np.sqrt( mnist.train.images.shape[1] ))\n",
    "pixel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 한개에 대한 레이블 크기\n",
    "pixels = mnist.train.images.shape[1]\n",
    "nums   = mnist.train.labels.shape[1]\n",
    "pixels, nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우의 CNN 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'x:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 채널 -> 손글시 이미지 데이터 -> n개(None),  이미지 1개당 특성(픽셀) pixels개\n",
    "x = tf.placeholder( tf.float32, shape=[None, pixels], name='x' )\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 출력 -> 손글씨가 0~9 로 레이블값 : 데이터 n개(None), 출력의종류,분류개수(nums)\n",
    "y_ = tf.placeholder( tf.float32, shape=[None, nums], name='y_')\n",
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (가중치, 필터, 커널)을 초기화하는 함수 구현 -> 여기, 저기에서 사용될것이다\n",
    "# name을 붙인 이뉴는 합성곱층마나다 사용이 될텐데, 이를 구분하기 위함\n",
    "# -> 텐서보드에서 그래프를 구분하기 위함\n",
    "def weight_variable(name, shape):\n",
    "    # 절단 정규 분포 함수\n",
    "    # 평균값을 기준으로 표준편차보다 크거가, 작은 데이터는 제외하는 난수 생성\n",
    "    # stddev: 표준편차\n",
    "    W_init = tf.truncated_normal(shape, stddev=0.1)\n",
    "    # 가중치 변수 생성\n",
    "    W = tf.Variable( W_init, name='W_' + name )\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바이어스(편향), 필터를 통과한 값을 전체적으로 올리거나, 내리거나\n",
    "def bias_variable(name, size):\n",
    "    # 0.1 설정값\n",
    "    b_init = tf.constant( 0.1, shape=[size] )\n",
    "    b = tf.Variable( b_init, name='b_' + name )\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 계층 생성\n",
    "def conv2d(x, W):\n",
    "    # 스트라이드 : 커널(필터, 가중치) 얼마 단위로 이동시킬것인가\n",
    "    return tf.nn.conv2d( x, W, strides=[1,1,1,1], padding='SAME' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.conv2d(\n",
    "    input,\n",
    "    filter=None,\n",
    "    strides=None,\n",
    "    padding=None,\n",
    "    use_cudnn_on_gpu=True,\n",
    "    data_format='NHWC',\n",
    "    dilations=[1, 1, 1, 1],\n",
    "    name=None,\n",
    "    filters=None\n",
    ")\n",
    "- input   : [batch, in_height, in_width, in_channels] \n",
    "    - batch : n 개의 이미지, 학습시키고자 하는 데이터의 개수\n",
    "    - in_height :  입력 데이터의 세로 크기 \n",
    "    - in_width :  입력 데이터의 가로 크기\n",
    "    - in_channels : 입력 채널, 흑백 -> 1, 칼라 -> 3(RGB)\n",
    "- filter  : [filter_height, filter_width, in_channels, out_channels] \n",
    "    - filter_height : 필터의 세로 \n",
    "    - filter_width  : 필터의 가로\n",
    "    - in_channels   : 입력 채널수\n",
    "    - out_channels  : 출력 채널수 \n",
    "- strides\n",
    "    - 슬라이딩 윈도우의 보폭 / 필터가 슬라이딩하는 폭\n",
    "    - [ batch, width, height, depth ]\n",
    "    - 통상 batch, depth는 1\n",
    "    - 통상적으로 width, height는 같은값 => 정사각형\n",
    "- padding\n",
    "    - strides가 이동하다보면, 공간이 않맞게 될수도 있다\n",
    "    - SAME 옵션을 주면 연산을 위해서 경계선을 채워준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱층 1 생성\n",
    "# 텐서 보드 상에서 그래프에 관련된 범위(scope)를 부여하여 관계를 쉽게 확인\n",
    "c_name1 = 'conv1'\n",
    "with tf.name_scope(c_name1) as scope:\n",
    "    # 5, 32는 설정한것이다\n",
    "    # 가중치 or 필터 or 커널 생성\n",
    "    #W_conv1 = weight_variable( c_name1, [filter_height, filter_width, in_channels, out_channels])\n",
    "    W_conv1 = weight_variable( c_name1, [5, 5, 1, 32])\n",
    "    # 편향 or 바이어스 생성\n",
    "    b_conv1 = bias_variable( c_name1, 32 )\n",
    "    # 입력 데이터에 대한 행렬 준비\n",
    "    #x_img = tf.reshape( x, [batch, in_height, in_width, in_channels] )\n",
    "    x_img = tf.reshape( x, [-1, pixel_size, pixel_size, 1] )\n",
    "    # 컨볼루젼 생성\n",
    "    # 활성화 함수를 사용 마감처리\n",
    "    h_conv1 = tf.nn.relu( conv2d( x_img, W_conv1 ) + b_conv1  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'conv1_1/Relu:0' shape=(?, 28, 28, 32) dtype=float32>>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_conv1.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 풀링층 생성 -> 크기를 대폭 줄여서, 데이터량을 줄이고, 특징은 유지\n",
    "# 최대풀링, 최소풀링등 존재\n",
    "# x의 shape : [?, 28, 28, 32]\n",
    "def max_pool(x):\n",
    "    # 2, 2는 설정값\n",
    "    return tf.nn.max_pool( x, ksize=[1, 2, 2, 1], \n",
    "                           strides=[1, 2, 2, 1], padding='SAME' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.max_pool(\n",
    "    value,\n",
    "    ksize,\n",
    "    strides,\n",
    "    padding,\n",
    "    data_format='NHWC',\n",
    "    name=None,\n",
    "    input=None\n",
    ")\n",
    "- value: x, [batch, height, width, channels], 합성곱층의 ReLU를 통과한 출력 결과\n",
    "- ksize: 입력 텐서에 대한 창(윈도우)의 크기, 통상적으로 strides와 동일값을 취한다\n",
    "- strides: 슬라이딩 윈도우의 보폭 / 필터가 슬라이딩하는 폭, [1, 2, 2, 1]라면 가로 2칸, 세로 2칸씩 이동해서 그 칸에 들어온 2x2 픽셀중 가장 큰값을 취하게 되므로, 가로가 1/2, 세로가 1/2로 축소된다\n",
    "- padding: 동일의미(위에)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('pool1') as scope:\n",
    "    h_pool1 = max_pool( h_conv1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'pool1/MaxPool:0' shape=(?, 14, 14, 32) dtype=float32>>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [?, 14, 14, 32], 이전층 대비 가로, 세로길이가 반으로 줄었다\n",
    "h_pool1.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱층2 생성 -> 출력 : 채널이 64로 늘어난다\n",
    "c_name2 = 'conv2'\n",
    "with tf.name_scope(c_name2) as scope:\n",
    "    W_conv2 = weight_variable( c_name2, [5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable( c_name2, 64 )    \n",
    "    h_conv2 = tf.nn.relu( conv2d( h_pool1, W_conv2 ) + b_conv2  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 풀링층2 생성 -> 출력 : 가로, 세로길이가 7로 즉, 다시 반으로 줄어든다\n",
    "with tf.name_scope('pool2') as scope:\n",
    "    h_pool2 = max_pool( h_conv2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'pool2/MaxPool:0' shape=(?, 7, 7, 64) dtype=float32>>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [?, 7, 7, 64]\n",
    "h_pool2.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전결합층\n",
    "# 현재 이미지의 크기는 합성곱층을 2번 통과 했으므로 => 28/2/2 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_name = 'fc'\n",
    "with tf.name_scope('fully_connected_layer') as scope:\n",
    "    n = 7 * 7 * 64\n",
    "    # 가중치 , 출력 채널을 1024개로 설정\n",
    "    W_fc = weight_variable( fc_name, [n, 1024] )\n",
    "    # 편향\n",
    "    b_fc = bias_variable( fc_name, 1024 )\n",
    "    # [-1, n] * [n, 1024] + [1024] = [-1, 1024]\n",
    "    h_pool2_fc = tf.reshape( h_pool2, [-1, n] )\n",
    "    # 활성화 함수 통과\n",
    "    h_fc = tf.nn.relu( tf.matmul( h_pool2_fc , W_fc ) + b_fc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'fully_connected_layer/Relu:0' shape=(?, 1024) dtype=float32>>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (?, 1024)\n",
    "h_fc.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과잉 적합 막기 (옵션)\n",
    "with tf.name_scope('dropout') as scope:\n",
    "    keep_prob = tf.placeholder( tf.float32 )\n",
    "    h_fc_drop = tf.nn.dropout( h_fc, rate=1-keep_prob )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'dropout/dropout/mul_1:0' shape=(?, 1024) dtype=float32>>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (?, 1024)\n",
    "h_fc_drop.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층 구성 - 활성화 함수로 softmax 사용\n",
    "ro_name = 'read_out'\n",
    "with tf.name_scope(ro_name) as scope:\n",
    "    W_ro   = weight_variable( ro_name, [1024, 10])\n",
    "    b_ro   = bias_variable( ro_name, 10 )\n",
    "    y_conv = tf.nn.softmax( tf.matmul( h_fc_drop, W_ro ) + b_ro )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'read_out/Softmax:0' shape=(?, 10) dtype=float32>>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (?, 10)\n",
    "y_conv.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실값 \n",
    "with tf.name_scope('loss') as scope:\n",
    "    # 크로스 엔트로피\n",
    "    # 비용(cost)/손실(loss) : 원하는 결과에 얼마나 떨어져 있는가. 이 격차를 줄이는데\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "with tf.name_scope('training') as scope:\n",
    "    # 확률적 경사 하강법\n",
    "    # 무작위로 초기화한 매개변수를 손실 함수가 작아지도록 지속적으로 반복하여 변경\n",
    "    optimizer  = tf.train.AdamOptimizer( 1e-4 )\n",
    "    train_step = optimizer.minimize( cross_entropy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "with tf.name_scope('predict') as scope:\n",
    "    predict_step   = tf.equal( tf.argmax( y_conv, 1 ), tf.argmax( y_, 1) )\n",
    "    accuracy_step  = tf.reduce_mean(tf.cast(predict_step, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 훈련 및 예측 평가시 사용할수 있는 구조로 변형 \n",
    "def set_feed( images, labels, prob ):\n",
    "    return { x:images  , y_:labels    , keep_prob:prob }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0 loss=575.8098 acc=0.1855\n",
      "step=100 loss=53.984283 acc=0.8272\n",
      "step=200 loss=31.580788 acc=0.8894\n",
      "step=300 loss=27.331343 acc=0.9162\n",
      "step=400 loss=22.057465 acc=0.9319\n",
      "step=500 loss=18.754917 acc=0.9389\n",
      "step=600 loss=14.779924 acc=0.9461\n",
      "step=700 loss=12.614549 acc=0.9512\n",
      "step=800 loss=9.283625 acc=0.9557\n",
      "step=900 loss=13.861797 acc=0.9579\n",
      "step=1000 loss=4.6125245 acc=0.9619\n",
      "step=1100 loss=13.500902 acc=0.9639\n",
      "step=1200 loss=9.945362 acc=0.9621\n",
      "step=1300 loss=5.4113398 acc=0.9673\n",
      "step=1400 loss=3.2832246 acc=0.9651\n",
      "step=1500 loss=8.034591 acc=0.9701\n",
      "step=1600 loss=6.333889 acc=0.9697\n",
      "step=1700 loss=9.862274 acc=0.9711\n",
      "step=1800 loss=5.3638167 acc=0.9729\n",
      "step=1900 loss=6.0039525 acc=0.975\n",
      "step=2000 loss=4.33366 acc=0.9729\n",
      "step=2100 loss=9.253002 acc=0.9757\n",
      "step=2200 loss=1.7749764 acc=0.9775\n",
      "step=2300 loss=4.2364573 acc=0.9758\n",
      "step=2400 loss=2.309727 acc=0.9784\n",
      "step=2500 loss=3.0060415 acc=0.9783\n",
      "step=2600 loss=0.29478785 acc=0.9782\n",
      "step=2700 loss=3.3752103 acc=0.9799\n",
      "step=2800 loss=0.9655623 acc=0.9803\n",
      "step=2900 loss=1.027688 acc=0.9788\n",
      "정확도 =  0.9808\n"
     ]
    }
   ],
   "source": [
    "# 세션 시작 -> 연산 시작\n",
    "with tf.Session() as sess:\n",
    "    # 텐서플로우 변수 초기화\n",
    "    sess.run( tf.global_variables_initializer() )\n",
    "    \n",
    "    # 테스트 전용 피드 데이터\n",
    "    test_fd = set_feed( mnist.test.images, mnist.test.labels, 1 )\n",
    "    \n",
    "    # 학습\n",
    "    for step in range( 3000 ): #10000 )\n",
    "        # 데이터를 50개씩 사용하겟다\n",
    "        # 훈련용 데이터에서 50개 획득\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        # 0.5 : 설정\n",
    "        fd = set_feed( batch[0], batch[1], 0.5 )\n",
    "        # 훈련\n",
    "        _, loss = sess.run( [train_step, cross_entropy], feed_dict=fd  )\n",
    "        # 100번째 마다 출력\n",
    "        if step % 100 == 0:\n",
    "            acc = sess.run( accuracy_step, feed_dict=test_fd )\n",
    "            print( 'step=%s loss=%s acc=%s'% (step, loss, acc))\n",
    "    # 최종 결과 출력\n",
    "    acc = sess.run( accuracy_step, feed_dict=test_fd )\n",
    "    print( '정확도 = ', acc)\n",
    "    \n",
    "    # 텐서보드 기록\n",
    "    tf.summary.FileWriter('./log_tf_cnn', graph=sess.graph)\n",
    "    \n",
    "    # 다 종료후\n",
    "    # $ tensorboard --logdir=log_tf_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
