1. 연구 목표
 - MovieLens (무비렌즈), 영화 평점 데이터
 - 사용자의 별점수를 예측
 - 개요
  > 2006년도 넷플릭스의 프라이즈 경진 대회가 가장 유명
  > 추천 정확도를 기존 대비 10% 향상을 목표 -> 모토 : "모든 것이 추천이다" 슬로건을 가지도 진행
    https://medium.com/NetflixTechBlog/5583 8468 f429
    https://medium.com/NetflixTechBlog/55838468f429
  > 무비렌즈 데이터는 미네소타에서 제공, 넷플릭스와 비슷한 정보를 기반으로 연구용으로 공개한 데이터
 
2. 시스템 정의
 - 추천 시스템
  > 목적 : 어떤 사용자 행동이나 아이템에 대한 정보로부터, 사용자가 선호할만한 관련 아이템을 제시하는것?  
  > 특징 : 검색만으로는 사용자가 원하는 콘텐츠를 찾기가 어려운경우(동영상/음악 스트리밍, 쇼핑몰)
           추천을 통해서 자신이 선호하는 콘텐츠를 발결하도록 도움을 주는 시스템
           => 서비스 제공자들도 상품 구매 전환율을 높이거나, 활성 사용자수를 늘리는 기회로 사용
 - 응용 분야
  > 개요 추천 : 
   1) 금주의 인기 상품 -> 통계 활용, 편집자 선택 아이템들을 추천
   2) 개인화가 되저 있지 않는 추천 -> 시스템을 처음 이용하는 사용자, 가끔 이용하는 사용자 적합
  > 사용자 평가 :
   1) 다른 사람의 추천 -> 그 아이템의 신뢰를 줄수있는 근거가 된다 -> 사용자는 스스로 납득을 하고 선택을 할수 있게 하는 방향으로 전개
   2) 다른 사용자의 별점, 댓글을 보여주거나, 평균 평점 노출
  > 알림 서비스 
   1) 푸시 / 이메일등을 통해 사용자가 흥미를 느낄 아이템을 추천 혹은 사이트 재방문 유도
  > 연관 아이템 추천
   1) 원래 아이템과 함계 연관된 아이템을, 그 정보를 제시하여 동시 구매를 유도, 
   2) 다른 아이템과 비교하게 함
   3) 전자 상거래의 정석
  > 개인화
   1) 인기 아이템 목록 / 편집자 추천 목록 => 사용자가 흥미를 느끼는 아이템을 노출, 사용자 마음에 드는 아이템을 찾도록 도움울 주는 시스템
   2) 검색 결과도 개인화를 적용

3. 데이터 설계 / 획득
 - 선호 데이터
  > 사용자가 특정 아이템을 얼마나 선호하는가?
 - 검색 쿼리
  > "7,000원이하 햄버거집" 검색  
 - 비평, 후기
  > 상품에 대한 업체에 대한 댓글평, 
 - 아이템 특징
  > 상품 설명에 쓰인 단어등에 대한정보  
 - 인구적 특징
  > 사용자의 연령, 성별  
 - 맥락적 특징
  > 추천받은 아이템을 사용한 날짜, 위치 정보, 재고 현황이런 데이터를 통한 맥락적, 연관적 정보

4. 영화 추천 기준  평가 데이터 관련
 - 데이터가 매우 희소하다, 많이 없다. 오래된 영화일수록 평가가 더 많다 문제 내포 => 추천시스템 구축이 어렵다!! 
 - 기준 평가
  > 사람마다 지금까지(현재시점) 본 영화가 모두 다르다.
  > 인기 영화는 평가 정보가 많다. 아닌 영화는 정보가 적다 => 추천이 않된다
  > 영화는 한해에 엄청나게 쏟아지는데, 한 사용자는 평생 볼수 잇는 영화수가 많지 않다. (상대적)
  > 평가 정보가 특정 아이템에 몰리게 될수 있고, 평점 행렬의 요소 대부분이 값을 가지지 않게 된다     => 결측치가 많다
  > 평점 행렬 : 각 사용자가 각 영화(아이템)에 대해 평점을 기재한 데이터 : 2차 행렬 
                   영화1   영화2   영화3
    --------------------------------------
    사용자1          5               1
    사용자2          4               2
    사용자3                  3       3
  > 선호 데이터 => 평가 정보 => 정답 데이터로 활용이 가능
  > 아이템의 평가 비용 ( 음악은 1곡을 듣고 평가를 수행할수 있다 => 3~5분=>상대적으로 선호 데이터를 구하기 쉽다) 
  > 주택 구입, 결혼식 예식장 선정등등 => 시간이 많이 소요 => 선호 데이터가 입수가 쉽지 않다 => 간접 지표를 통해서 선호데이터를 보충(페이지 노출, 클릭, 머문시간등등)

5. 선호 데이터 수집 방법 : 명식적 데이터 /묵시적 데이터
 - 명식적 데이터
  > 사용자에게 직접, 선호도를 물어서 답변을 구하는 방식  
 - 묵시적 데이터
  > 상품을 구매하거나, 상품 정보를 열람(기웃 기웃거린다) => 이 아이템에 흥미를 가지고 있다 => 이런 데이터를 모으는 방법
                                  명시적        묵시적
  ---------------------------------------------------
    데이터양                         X             O
    데이터의 정확성                  O             X
    미평가와 부정적 평가 구분        O             X
    사용자의 인지성                  O             X

6. 추천 시스템 알고리즘
 - 협업 필터링 : collaborative filtering
 
  > 메모리 기반 협업 필터링 : memory-based collaborative filtering
 
   1) 사용자 기반 협업 필터링 : user-based collaborative filtering
      -> 당신과 비슷한 상품을 산 고객은 이런 상품도 샀다
      1) 피어슨 상관관계, 코사인 유도, 자카드 계수등 등장
   
   2) 아이템 기반 협업 필터링 : item-based collaborative filtering
      -> 방금 막 가입한 사용자에게 적용하기에 적합
  
  > 모델 기반 협업 필터링 : model-based collaborative filtering
    -> 회귀/분류등 예측 모델을 학습해서 처리
    
 - 내용 기반 필터링 : content-based filtering
   -> 영화라면 메타정보(제목,감독,장르,배우,평판등등 간접지표를 통해 나타나는 정보에 주목)
 
7. 사용자 기반 협업 필터링
 [ 나와 비숫한 사용자는 어떻게 찾지 => 여러개의 요소중에 평점을 기준으로 하겟다 =>
   평점행렬을 구성 => 유사도를 측정 => 그 기반 기술 : 피어슨 상관관계, 코사인 유도, 자카드 계수
   가 있다 ]
 - 당신과 비슷한 상품을 산 고객은 이런 상품도 샀다
 - 사용자와 아이템의 쌍에 대한 평점 행렬이 있는 경우, 행렬에 누락된 요소에 해당하는 평점을 예측
  1) 사용자 정보를 백터로 표현
  2) 사용자간의 유사도를 평가 
  3) 방법
   평점 행렬  => rating[사용자별영화별평가점수인덱스][영화별인덱스]
   i번째 사용자(user[i]) U의 평점백터 u = [ rating[i][0], rating[i][3], rating[i][m] ]
   j번째 사용자(user[j]) V의 평점백터 v = [ rating[j][0], rating[j][3], rating[j][m] ]
   => 유사도값: 대상이 비슷하면 값이 커지고, 다르면 작아지는 척도(기준 지표)
   [ numpy 직접 구현 , scipy 함수로 지원 ]
   a) 피어슨 상관관계 : 
    ->  가장 일반적인 상관 계수
    ---------------------------------------------------------------
    [numpy]
    import numpy as np
    def person_coefficient_law( u, v ):
        u_diff = u - np.mean(u)
        v_diff = v - np.mean(v)
        return np.dot( u_diff, v_diff ) 
               / ( np.sqrt( sum( u_diff ** 2 ) ) * np.sqrt( sum( v_diff ** 2) ) )
    ---------------------------------------------------------------
    [scipy]
    from scipy.spatial.distance import correlation
    # 피어슨 상관관계
    def person_coefficient( u, v ):
        return 1 - correlation( u, v)
    
   b) 코사인 유도
    -> 텍스트 문장 간의 거리를 측정하는 척도용
    ---------------------------------------------------------------
    # 코사인 유도
    from scipy.spatial.distance import cosine
    def cosine_similarity( u, v ):
        return 1 - cosine( u, v)
    ---------------------------------------------------------------
    # 코사인 유도 직접 구현
    import numpy as np
    def cosine_similarity_law( u, v ):
        return np.dot( u, v ) / ( np.sqrt( sum( u ** 2 ) ) * np.sqrt( sum( v ** 2) ) )
    
   c) 자카드 계수등 등장
    -> 집합과 집합 사이의 거리를 계산, 0~1로만 존재
    ---------------------------------------------------------------
    from scipy.spatial.distance import jaccard
    def jaccard_similarity( u, v ):
        return 1- jaccard(u, v)
    ---------------------------------------------------------------
    # 자카드 계수 직접 구현
    import numpy as np
    def jaccard_similarity( u, v ):
        return np.dot( u, v ) / ( sum(np.absolute(u)) + sum(np.absolute(v)) - np.dot(u,v)  )

8. 아이템 기반 협업 필터링
 - 방금 막 가입한 사용자에게 적용하기에 적합
 - 활동이 아주 저조한 유저에게도 적용하기에 적합
 - 단, 예상되는 문제점은 인기 아이템만 노출이 집중되는 문제가 있어서, 이외의 아이템들을 노출하는 보강 작업이 필요로 하다
 - 사용자 기반 협업 필터링과 유사점이 있고, 코사인 유도를 개선된 방식으로 사용
   adjusted cosine similarity : 개선된 코사인 유도
 - 영화 평점 M의 평점 백터를 m
   영화 N의 평점 백터를 n
   사용자 평균 평점 u_mean
   ----------------------------------
   [numpy에서 구현]
   # 개선된 코사인 유도 
   import numpy as np
   def adjusted_cosine_similarity( m, n, u_mean ):
        ad_m = m - u_mean
        ad_n = n - u_mean
        return np.dot( ad_m, ad_n ) / ( np.sqrt( sum( ad_m ** 2 ) ) * np.sqrt( sum( ad_n ** 2) ) )

9. 모델 기반 협업 필터링
 - 회귀/분류등 예측 모델을 학습해서 처리 => 비도/비지도 학습방법을 이용하여
   기존 데이터가 가지는 규칙성에 따라 예측 및 추천하는 방법
 - 방법적 예
   a) 군집화를 사용하는 모델 -> 비지도 학습
    - 선호도가 비슷한 사용자들을 그룹을 묶고, 특정 사용자가 자신이 속한 그룹이 선호하는 아이템을 추천
   b) 평점에 대한 회귀 모델
    - 선형 회귀
    - 모델 학습후 평점 예측
    - 이 평점 기준으로 그 점수에 도달해 있는 작품들을 추천(방법론은 좀더 확장)    
   c) 토픽을 이용한 모델
    - 멜로 장르 선호, sf 선호등 잠재적인 의미를 드러내는 기법
    - 묵시적 데이터로 획득 가능
    - 방법
      1) 확률적 잠재 의미 분석 : PLSA 
      2) 잠재 디리클레 할당 : LDA 
    
   d) 행렬분해 (행렬 인수분해 -> fastFM, libFM 이런 기능을 지원)
    - 코드예에서 사용
    

10. 내용 기반 필터링
 - 영화라면 메타정보(제목,감독,장르,배우,평판등등 간접지표를 통해 나타나는 정보에 주목)
 - 이런 정보들의 과거 정보들 이용하여 추천 항목 구성/선택
 - 이런 정보속에 사용자의 취향을 표출하는 단어를 알수 있다면(발견되면) 그 정보를 통해서
   취향에 맞는 영화들을 제시할 수 있다
 
11. 비교 (협업 필터링 <-> 내용 기반 필터링)
 - 협업 필터링
  > 장르, 텍스트등에 포함된 단어에 유사점이 없어도, 다양한 추천 결과를 얻을수 있는 가능성이 크다
  > 도메인에 대한 지식, 관리할 필요도 없다
  > 문제점 : 데이터가 충분히 쌓이기 전까지 -> 신규사용자에게 새로운 아이템 추천 불가 
    => 콜드 스사트 문제 
    => 사용자가 적으면 준비된 추천 알고리즘을 적용한 추천이 자체가 불가능하고 -> 사용자가 늘지 않고 => 데이터가 없고 -> 추천이 불가능한 악순황에 빠질수 있다 => 초반 전략과, 데이터가 확보된 이후 전략을 달리하거나 적절이 섞어서 구현
  > 아이템 기반 협업 필터링같은 방식을 이용하여 누적 행동 데이터등 누적 데이터가 없는 상황에서도 적절한 추천을 수행할수 있다    
 
 - 내용 기반 필터링
  > 아이템의 내용을 기초로 누적 행동 데이터가 없어도 적절한 추천이 가능
  > 한국어 => 형태소 분석, 유지 보수측면등등 도메인에 특화된 이슈들이 제법 존재한다
 
  
12. 평가 척도 
 - 분류 방식의 평가
  > 정확도 : accuracy
   1) 5단계 평점에서 4점이상 받으면 정답으로 간주 -> label화
   2) 예측결과와 사용자의 평점을 비교
   3) 정밀도 : precision -> 예측 결과중 실제 정답의 비율
   4) 재현율 : recall    -> 전체정답 중 실제 정답을 맞춘 비율  
 - 회귀 방식의 평가
  > 회귀로 예측한 별점의 개수등 이런 형태로 추천 사용. 
  > RMSE : 평균 제곱근 오차 : Root  mean squared error
   -> 예측값과 실제값의 차이를 제곱한 갑
   -> 오차가 클수록 평귱제곱근값도 커진다 -> 작을수록 정확해 지는 특징
      MAE 대비 이상값에 취약한 단점을 가지고 있다.
  > MAE  : 평균 절대 오차   : Mean absolute error
   -> 예측값과 실제값의 차이에 대한 절대값으로부터 평점을 계산
   -> 예측값과 실제값의 오차가 클수록 평균 절대 오차도 커진다
 - 순위상관
  -> 추천한 아이템의 순서를 평가하는 지표 -> 랭킹학습
 - 커버지리
  -> 다양성을 평가 지표에 포함시켜, 전체 아이템 중에서 평점을 예측할수 있는 아이템의 비율로 평가를 수행
  

13. 분석및 데이터 획득
 - 목표 
  > 무비렌즈 데이터를 이용하여 추천 시스템을 구축한다 -> 상황인지추천
  > 상황인지추천 : 사용자와 아이템 정보외의 정보를 활용하여 추천하는 방식
 - 데이터 획득
  [데이터다운로드]
  > wget http://files.grouplens.org/papers/ml-100k.zip
  [압축해제]
  > unzip ml-100k.zip
  
14. docker 
 - 오프소스 라이브러리 중에는 윈도우에서 설치가 않되는 유형이 제법 존재한다
 - 보편적으로 리눅스에서는 모두 작동하므로, 도커를 이용하여 리눅스 이미지를 구축하고,
   우분트 18.04(late) 기반에서 환경을 구축하고, fastFM (인수분해머신기능 지원)를 
   컴파일(os에 적합하게 -> *.o 생성) 후 설치
 - 이렇게 구축된 추천시스템 라이브러리가 적용된 우분트 이미지를 도커허브에 올려서, 
   어떤 PC든지 재구축시 빠르게 구성할수 있다
 - 향후 딥러닝 머신을 사용시 도커를 이용하여 구축하여, 각기 자유롭게 사용이 가능하고,
   하둡 클러스터의 시스템 베이스로 사용 가능하다





