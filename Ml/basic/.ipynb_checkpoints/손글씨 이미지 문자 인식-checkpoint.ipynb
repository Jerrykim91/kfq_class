{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손글씨 이미지 데이터 MINST\n",
    "\n",
    "- 많은 이미지 데이터 학습\n",
    "- 학습후 새로운 데이터 입력시 판별\n",
    "- 지도 학습\n",
    "- 데이터는 학습용 6만개, 테스트 전용 1만개 \n",
    "- http://yann.lecun.com/exdb/mnist/\n",
    "  > train-images-idx3-ubyte.gz:  training set images (9912422 bytes)   \n",
    "  > train-labels-idx1-ubyte.gz:  training set labels (28881 bytes)   \n",
    "  > t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes)   \n",
    "  > t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|절차|단계|목표/설명|\n",
    "|:---|---:|:---:|\n",
    "|1|연구목표|- 손글씨 이미지(숫자:0~9) 학습시켜서, 이후에 새로운 손글씨 이미지를 판별해 내는 머신러닝 모듈 구현<<BR>-이미지 데이터를 디코딩하여, 이미지 하나당 구성된 총 픽셀수 및 사이즈를 계산하여 이미지를 추출한다 => 디코딩과정 => 6만개의 데이터를 생성<BR>- 이미지와 같은 바이너리 데이터를 백터화 하는 과정 |\n",
    "|2|데이터획득/수집|- http://yann.lecun.com/exdb/mnist/ 접속<BR> - 데이터수집 LEVEL3 Web Scraping을 활용하여 압축 데이터를 받는 URL을 획득<BR> - 압축데이터를 집적 요청하여 받고 저장하면서 압축 풀고등 일련의 과정 진행|\n",
    "|3|데이터준비/통찰/전처리|- MNIST database 구조 이해<br>-디코딩처리가 가능<br>-엔디언(Endiann) 내용 추가로 이해|\n",
    "|4|데이터탐색/통찰/시각화|skip|\n",
    "|5|데이터모델링 or 모델구축||\n",
    "|6|시스템통합 or (솔류션,서비스,레포트)||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 데이터획득/수집\n",
    "\n",
    "- 2-1. 수집할 데이터 URL 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup 생성\n",
    "baseUrl = 'http://yann.lecun.com/exdb/mnist/'\n",
    "soup    = BeautifulSoup( req.urlopen(baseUrl), 'html5lib' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.gz\n",
      "train-labels-idx1-ubyte.gz\n",
      "t10k-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "for tt in soup.findAll( 'tt' )[:4]:\n",
    "    # href 값이나, 링크의 문자열이나 동일하다\n",
    "    print( tt.a.string )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train-images-idx3-ubyte.gz',\n",
       " 'train-labels-idx1-ubyte.gz',\n",
       " 't10k-images-idx3-ubyte.gz',\n",
       " 't10k-labels-idx1-ubyte.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gz 파일 4개 URL 획득 => 리스트에 담는다 \n",
    "files   = [ tt.a.string  for tt in soup.findAll( 'tt' )[:4] ]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2-1. 압축 데이터를 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path, gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장 위치 선정\n",
    "savePath = './data/mnist'\n",
    "# 해당 디렉토리가 없으면 생성해라\n",
    "if not os.path.exists( savePath ): # 물리적으로 존재하지 않는가?\n",
    "    #os.mkdir( savePath ) # 체킹\n",
    "    os.makedirs( savePath )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f4166752374221bb5062282c742895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본데이터주소 http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "저장될 데이터의 경로 ./data/mnist/train-images-idx3-ubyte.gz\n",
      "원본데이터주소 http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "저장될 데이터의 경로 ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "원본데이터주소 http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "저장될 데이터의 경로 ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "원본데이터주소 http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "저장될 데이터의 경로 ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 저장\n",
    "from tqdm import tqdm_notebook\n",
    "for file in tqdm_notebook(files):\n",
    "    print( '원본데이터주소',  baseUrl + file )\n",
    "    \n",
    "    local_path = '%s/%s' % (savePath , file)\n",
    "    print( '저장될 데이터의 경로',  local_path )\n",
    "    \n",
    "    # 이미 파일이 존재하면 새로 받지 않겟다\n",
    "    if not os.path.exists( local_path ):\n",
    "        # 웹상에 존재하는 리소스를 로컬에 직접 저장(위치지정)\n",
    "        req.urlretrieve( baseUrl + file, local_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2-2. 압축 데이터 압축 해제 :  gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720da5fe7dcf4b499c8b674c0e3cb505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/mnist/train-images-idx3-ubyte.gz ./data/mnist/train-images-idx3-ubyte\n",
      "./data/mnist/train-labels-idx1-ubyte.gz ./data/mnist/train-labels-idx1-ubyte\n",
      "./data/mnist/t10k-images-idx3-ubyte.gz ./data/mnist/t10k-images-idx3-ubyte\n",
      "./data/mnist/t10k-labels-idx1-ubyte.gz ./data/mnist/t10k-labels-idx1-ubyte\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 이름 규칙 => train-images-idx3-ubyte.gz => 압축해제 => train-images-idx3-ubyte\n",
    "for file in tqdm_notebook(files):\n",
    "    # 원본 파일\n",
    "    ori_file = '%s/%s' % (savePath , file)\n",
    "    # 압축해제 파일\n",
    "    raw_file = '%s/%s' % (savePath , file[:-3]  )\n",
    "    print(ori_file, raw_file)\n",
    "    # 압축파일을 오픈 => 읽어서 => 기록\n",
    "    # 압축파일 오픈\n",
    "    with gzip.open( ori_file, 'rb' ) as fg:\n",
    "        # 내용을 읽고\n",
    "        # 만약 대용량이면, 분할해서 읽어야 한다 \n",
    "        tmp = fg.read() \n",
    "        with open(raw_file, 'wb') as f:\n",
    "            f.write( tmp )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 데이터준비/통찰/전처리\n",
    "\n",
    "- 디비구조 이해상 나온 내용: \n",
    "- 엔디언/에디언 : 컴퓨터 메모리와 같은 1차원의 공간에 여러개의 연솓된 데이터를 배열하는 방법 -> 오더링:ordering -> 바이트오더:byte order\n",
    "- 값 : 0x12345678\n",
    "- 빅 에디언: \n",
    " \n",
    "|메모리|...|0x100|0x101|0x102|0x103|...|\n",
    "|:---|---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|값|...|0x12|0x34|0x56|0x78|...|\n",
    "\n",
    "- 리틀 에디언:\n",
    "\n",
    "|메모리|...|0x100|0x101|0x102|0x103|...|\n",
    "|:---|---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|값|...|0x78|0x56|0x34|0x12|...|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label의 구조\n",
    "\n",
    "- 구조\n",
    " > magic number : 4 byte  \n",
    " > label 개수   : 4 byte  \n",
    " > label        : 1 byte  ,....\n",
    "\n",
    "\n",
    "#### images 구조\n",
    "- 구조\n",
    " > magic number : 4 byte    \n",
    " > image 개수   : 4 byte  \n",
    " > 이미지 가로  : 4 byte  \n",
    " > 이미지 세로  : 4 byte  \n",
    " > 이미지       : 28*28 byte ,...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블데이터, 원데이터를 읽어서 => 풀어서 데이터를 저장\n",
    "# t10k-images-idx3-ubyte\n",
    "# t10k-labels-idx1-ubyte\n",
    "# train-images-idx3-ubyte\n",
    "# train-labels-idx1-ubyte\n",
    "# 훈련용 데이터, 테스트용 데이터 각각 처리 => 같은 구조로 2세트 => 함수로 처리\n",
    "# 실데이터는 어디에 저장할것인가? -> csv 저장해보겟다 and 저장(*.pgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_minist_rawData( dataType='train', maxCnt=0 ):\n",
    "    # 레이블 파일 읽기 모드 오픈\n",
    "    label_f = open( '%s/%s-labels-idx1-ubyte' % (savePath, dataType), 'rb' )\n",
    "    # 이미지 데이터 파일 읽기 모드 오픈\n",
    "    image_f = open( '%s/%s-images-idx3-ubyte' % (savePath, dataType), 'rb')\n",
    "    # csv 쓰기 모드 오픈(train.csv)\n",
    "    csv_f   = open( '%s/%s.csv' % (savePath, dataType), 'w', encoding='utf-8')\n",
    "    # -------------------------------------------------------------------\n",
    "    \n",
    "    # 디코딩을 위한 헤더 정보 추출\n",
    "    # 매직코드나 사이즈, 이미지의 가로, 세로 정보등응 획득하기 위해서는 \n",
    "    # 4바이트씩 읽어서 빅에디안(high endian) 처리를 해야한다 -> struct 모듈해결\n",
    "    # label\n",
    "    # >II => 읽은 총데이터를 2번(로) 나눠서 각각 변수에 담아라\n",
    "    # > => 빅에디안\n",
    "    magic, label_count = struct.unpack( '>II', label_f.read(8) )\n",
    "    print( magic, label_count )\n",
    "    # image , 파일포인터(커서)는 위치는 16\n",
    "    magic, image_count, row, col = struct.unpack( '>IIII', image_f.read(16) )\n",
    "    print( magic, image_count, row, col )\n",
    "    # 이미지 한개당 총 픽셀수 \n",
    "    pixels = row * col\n",
    "    \n",
    "    # 데이터를 추출(디코딩)해서 csv에 저장\n",
    "    for idx in range( label_count ):\n",
    "        # 데이터를 원하는 만큼 세팅했다\n",
    "        if idx >= maxCnt:break\n",
    "        # ------------------------------------------------------------\n",
    "        \n",
    "        # 정답 추출 -> 1 byte만 읽으면된다 -> unsignde byte -> 'B'\n",
    "        label_tmp = struct.unpack( 'B', label_f.read(1) )        \n",
    "        #print( label_tmp )\n",
    "        # 값이 결측치에 해당될 경우 -> 이미지 데이터로 같이 날린다\n",
    "        if len(label_tmp) != 1:\n",
    "            continue\n",
    "        # 라벨값, 정답 획득\n",
    "        label = label_tmp[0]\n",
    "        # -----------------------------------------------------------\n",
    "        \n",
    "        # 이미지 추출 => 얼마큼 읽어야 하는가?\n",
    "        # 이미지 데이터 원본은 에디안하고는 관계 없다.여러바이트를 쓰는\n",
    "        # 정수가아닌 데이터 자체이므로 무관\n",
    "        binarryData = image_f.read(pixels)\n",
    "        #print( type(binarryData) )        \n",
    "        # 픽셀값 하나 하나를 문자열로 만들어서 리스트에 담아라\n",
    "        strData = list( map( lambda x: str(x), binarryData ) )\n",
    "        #  csv에 기록 : label, 이미지데이터 줄바꿈\n",
    "        csv_f.write( str(label)+',' )\n",
    "        csv_f.write( ','.join( strData )+'\\n' )\n",
    "        \n",
    "        # 해당 데이터를 별도로 저장하여 이미지로 파일로 보관\n",
    "        # 대략 10개정만 저장\n",
    "        # 손글시 확인 : http://paulcuth.me.uk/netpbm-viewer/\n",
    "        if idx < 10:\n",
    "            # pqm 파일로 저장\n",
    "            fName = '{0}/{1}-{2}-{3}.pgm'.format(savePath, dataType, idx, label)\n",
    "            # pqm 헤더\n",
    "            header = 'P2 28 28 255\\n'\n",
    "            s      = header + ' '.join( strData )\n",
    "            # 파일기록\n",
    "            with open( fName, 'w', encoding='utf-8' ) as f:\n",
    "                f.write( s )\n",
    "            \n",
    "\n",
    "    # 파일닫기\n",
    "    label_f.close()\n",
    "    image_f.close()\n",
    "    csv_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,0,0,0,0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(['0', '0', '0', '0', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2049 60000\n",
      "2051 60000 28 28\n",
      "2049 10000\n",
      "2051 10000 28 28\n"
     ]
    }
   ],
   "source": [
    "decode_minist_rawData( dataType='train',  maxCnt=750 )\n",
    "decode_minist_rawData( dataType='t10k',   maxCnt=250 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 데이터탐색/통찰/시각화\n",
    "\n",
    "- 데이터는 현재  csv에 저장되어 있다. 이를 로드해서 데이터를 전처리 하여 학습에 적합한 구조로 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/mnist/train.csv', './data/mnist/t10k.csv')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 csv 파일 경로\n",
    "savePath + '/' + 'train' + '.csv', savePath + '/' + 't10k' + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. csv를 오픈\n",
    "# 2. csv를 읽는다 -> 데이터 한줄(row)을 읽어서 리스트에 맴버로 담는다\n",
    "#    ex) train.csv를 리스트에 750개의 맴버가 생성, t10k는 250개 생성\n",
    "#    [ [],[],[],[], ]\n",
    "# 3. 리스트의 맴버(리스트)는 0번맴버가 레이블, 1번~ 마지막까지가 픽셀인데, \n",
    "#    픽셀은 현재 0 ~255까지 값으로 구성, 학습 성능을 높이기 위해 \n",
    "#    픽셀값을 0 ~ 1(255)사이로 정규화 하여 배치. 1, 28*28개\n",
    "# { 'labels':labels, 'images':images }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv( dataType='train' ):\n",
    "    # 1. csv를 오픈\n",
    "    fName = '{}/{}.csv'.format( savePath, dataType )\n",
    "    print( fName )\n",
    "    labels = []\n",
    "    images = []\n",
    "    with open( fName, 'r' ) as f:\n",
    "        # 2. csv를 읽는다 \n",
    "        #print( len( f.readline() ) )\n",
    "        for line in f: # for문을 이용하여 한줄씩 리드 하는 표현\n",
    "            #print( type(line), line )\n",
    "            # 데이터를 들여다 보니, 785개의 데이터는 모두 ,로 구분되어있다->분해\n",
    "            tmp = line.split(',')\n",
    "            #print( len(tmp), type( int(tmp[0]) ) )\n",
    "            # labels에 답(0~9) 데이터를 정수값으로 세팅 -> 1차 리스트\n",
    "            labels.append( int(tmp[0]) )\n",
    "            #break            \n",
    "            # images에 [ 28*28개의 픽셀값 ] 맴버로 추가 -> 2차 리스트\n",
    "            #images.append( tmp[1:] )\n",
    "            images.append( list( map( lambda x: int(x)/256, tmp[1:] ) ) )\n",
    "            \n",
    "            # => 단, 데이터는 0~1까지 정규화 진행된 값\n",
    "            # 255로 정규화, 256으로 정규화하는 것인가?\n",
    "            # 데이터 자체를 들여다 보면 => 픽셀 데이터는 앞뒤로 영향을 받는 \n",
    "            # 연속적인 성향을가진 값인자, 독립적인 값인지 검토\n",
    "            # 수치값 -> 연속변수(255:최대값기준), 분류변수(256:총개수기준)\n",
    "            \n",
    "            # python => list( map( 함수, 데이터덩어리 ) )\n",
    "            # pandas => 데이터덩어리 = 데이터덩어리.apply( 함수 )\n",
    "    \n",
    "    \n",
    "    return { 'labels':labels, 'images':images  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나름 최적화 \n",
    "def load_csv( dataType='train' ):    \n",
    "    fName = '{}/{}.csv'.format( savePath, dataType )    \n",
    "    labels = []\n",
    "    images = []\n",
    "    with open( fName, 'r' ) as f:        \n",
    "        for line in f:\n",
    "            tmp = line.split(',')            \n",
    "            # tmp.pop(0) : 0번 맴버를 제거하고, 리턴\n",
    "            labels.append( int(tmp.pop(0)) )        \n",
    "            # len(tmp) => 784개로 1개 줄어들었다\n",
    "            images.append( list( map( lambda x: int(x)/256, tmp ) ) )            \n",
    "    return { 'labels':labels, 'images':images  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_csv(  )\n",
    "test  = load_csv( dataType='t10k' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 데이터모델링 or 모델구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알고리즘 선택 => 파이프라인 구축 \n",
    "from sklearn import svm, model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알고리즘 생성 => 파이프라인 구축, 하이퍼파라미터 튜닝\n",
    "clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터분류 (이미 되어 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 \n",
    "clf.fit( train['images'], train['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 (테스트 데이터 사용)\n",
    "predict = clf.predict( test['images'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.788"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인, 결과 리포트 => 성능 평가\n",
    "ac_score = metrics.accuracy_score( test['labels'], predict )\n",
    "ac_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       0.79      1.00      0.88        34\n",
      "          2       0.70      0.67      0.68        24\n",
      "          3       0.86      0.52      0.65        23\n",
      "          4       0.79      0.79      0.79        33\n",
      "          5       0.68      0.84      0.75        25\n",
      "          6       1.00      0.64      0.78        22\n",
      "          7       0.81      0.76      0.79        29\n",
      "          8       0.92      0.79      0.85        14\n",
      "          9       0.65      0.81      0.72        27\n",
      "\n",
      "avg / total       0.80      0.79      0.79       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_report = metrics.classification_report( test['labels'], predict )\n",
    "print( cl_report )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 풀세트 구성 후 => 반복작업 : 본 칸에 반복작업 구성\n",
    "decode_minist_rawData( dataType='train',  maxCnt=60000 )\n",
    "decode_minist_rawData( dataType='t10k',   maxCnt=10000 )\n",
    "\n",
    "clf = svm.SVC()\n",
    "\n",
    "train = load_csv(  )\n",
    "test  = load_csv( dataType='t10k' )\n",
    "\n",
    "clf.fit( train['images'], train['labels'] )\n",
    "\n",
    "predict = clf.predict( test['images'] )\n",
    "\n",
    "ac_score = metrics.accuracy_score( test['labels'], predict )\n",
    "print( ac_score )\n",
    "\n",
    "cl_report = metrics.classification_report( test['labels'], predict )\n",
    "print( cl_report )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
